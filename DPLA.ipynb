{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the DPLA API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code to interact with the DPLA API. Designed specifically to produce output suited to further, manual data entry, for eventual conversion to RDF according to the [Collex standard](http://wiki.collex.org/index.php/Main_Page)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Search DPLA and return results as tsv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from dpla_api import DplaApi\n",
    "\n",
    "# Quoted search terms should be put inside double quotes, then single quotes.\n",
    "# For example: '\"civil rights\"'\n",
    "search_term = '\"emmett till\"'\n",
    "fields = []\n",
    "\n",
    "da = DplaApi()\n",
    "# Run search, page_size is capped (by DPLA) at 500, but code will iterate through \n",
    "# as many pages as necessary to gather all results.\n",
    "da.search(search_term, page_size=500, fields=fields) \n",
    "# All retrieved results will be stored in the da.metadata_records object.\n",
    "da.build_arc_rdf_dataset(check_match=False)\n",
    "da.create_tsv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check values within results. (Not usually necessary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "errors = 0\n",
    "for r in da.all_returned_items:\n",
    "    if \"subject\" in r[\"sourceResource\"]:\n",
    "        for s in r[\"sourceResource\"][\"subject\"]:\n",
    "            if \"name\" not in s:\n",
    "                errors += 1\n",
    "                print r[\"sourceResource\"][\"subject\"]\n",
    "                print r\n",
    "            \n",
    "print errors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Transform TSV records to RDF\n",
    "\n",
    "Once complete with any necessary changes, the tsv file can be used to create RDF records."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from buildrdf import BuildRdf\n",
    "\n",
    "input_path = \"/Users/higgi135/Downloads/Gay liberation.tsv - Sheet1.tsv\"\n",
    "output_path = \"rdf/gldplatest2.rdf\"\n",
    "\n",
    "br = BuildRdf()\n",
    "br.build_rdf_from_tsv(input_path, output_path) # first input file, then output file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below is an implementation for running a specific set of searches drawn from a json file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from dpla_api import DplaApi\n",
    "import json\n",
    "da = DplaApi()\n",
    "with open(\"mich-results.json\") as f:\n",
    "    data = json.load(f)\n",
    "da.create_tsv(records=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import json\n",
    "with open(\"mich-results.json\", \"w\") as f:\n",
    "    json.dump(da.metadata_records, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from dpla_api import DplaApi\n",
    "import json\n",
    "da = DplaApi()\n",
    "all_metadata = []\n",
    "search_file = \"data/dpla_subjects.json\"\n",
    "with open(search_file) as f:\n",
    "    search_terms = json.load(f)\n",
    "# Disciplines, in this case, is an extra data point useful for creating\n",
    "# the brand of RDF used in the SiRO project.\n",
    "for search_term, disciplines in search_terms.items():\n",
    "    if len(da.metadata_records) > 10000:\n",
    "        break\n",
    "    else:\n",
    "        da.search(search_term, page_size=500)\n",
    "        if da.result.count > 0:\n",
    "            da.build_arc_rdf_dataset(disciplines=disciplines)\n",
    "            # all_metadata += da.metadata_records\n",
    "# Create a TSV file of output for closer analysis / update of terms.\n",
    "da.create_tsv(records=da.metadata_records)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to make sure each successive bath of DPLA results doesn't simply reintroduce the results of any previous batches, there is a listing of all previously encountered results stored in a JSON file. An on-the-fly version is updated with searches as they complete, _however_ this cache should be cleared if these search results don't wind up making it into RDF records, by using the `reset_matches` parameter below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from dpla_api import DplaApi\n",
    "da = DplaApi()\n",
    "da.update_rdf_registry(reset_matches=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Build json file of search terms.\n",
    "import json\n",
    "subject_file = \"data/estc_subjects.tsv\"\n",
    "subject_dict = {}\n",
    "with open(subject_file) as f:\n",
    "    for line in f:\n",
    "        values = line.split(\"\\t\")\n",
    "        if values[1] == \"x\":\n",
    "            subject_dict[values[0]] = values[2]\n",
    "with open(\"data/dpla_subjects.json\", \"w\") as g:\n",
    "    json.dump(subject_dict, g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "da._marc_record(da.all_returned_items[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for item in da.all_returned_items:\n",
    "    if da._get_genre_from_marc(item) != \"none\":\n",
    "        print da._get_genre_from_marc(item)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
